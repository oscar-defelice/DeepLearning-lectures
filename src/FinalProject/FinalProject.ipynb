{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img width=\"699\" alt=\"image\" src=\"https://user-images.githubusercontent.com/49638680/159042792-8510fbd1-c4ac-4a48-8320-bc6c1a49cdae.png\">\n",
    "</p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-Aq6rE2ri9v"
   },
   "source": [
    "# Text Classification problem\n",
    "\n",
    "Here we want to solve a famous text classification problem.\n",
    "We have the Sentiment 140 Twitter dataset (available [here](https://www.tensorflow.org/datasets/catalog/sentiment140) or in the tensorflow dataset library).\n",
    "\n",
    "The main objectives are:\n",
    "1. Show a *brief* preliminary analysis of the data (classes are balanced, useful informations, feature selection, etc)\n",
    "2. Show some visualisation.\n",
    "3. Answer questions (later)\n",
    "4. Train a model with a test accuracy over the $80\\%$.\n",
    "5. *Optional* Deploy the model on a webpage through Tensorflow.js\n",
    "\n",
    "**Bonus**: make me learn something I did not know ðŸ™‚.\n",
    "\n",
    "#### Important note\n",
    "Any choice has to be properly explained and justified.\n",
    "\n",
    "<details>\n",
    "    <summary><b>HINT</b></summary> \n",
    "    \n",
    "    Make use of open-source implementations of similar problems you can easily find online!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkWoHEJ-s69z"
   },
   "source": [
    "## The dataset\n",
    "<details>\n",
    "    <summary><b>Click to Expand</b></summary> \n",
    "    \n",
    "We will use [twitter_sentiment dataset](https://www.tensorflow.org/datasets/catalog/sentiment140).\n",
    "\n",
    "### What is Sentiment140?\n",
    "\n",
    "Sentiment140 allows you to discover the sentiment of a brand, product, or topic on Twitter.\n",
    "\n",
    "### How does this work?\n",
    "You can read about our approach in our technical report: [Twitter Sentiment Classification](http://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf) using Distant Supervision. There are also additional features that are not described in this paper.\n",
    "\n",
    "### Who created this?\n",
    "Sentiment140 was created by Alec Go, Richa Bhayani, and Lei Huang, who were Computer Science graduate students at Stanford University.\n",
    "\n",
    "    \n",
    "**Note**: you can directly download the dataset from [tensorflow datasets](https://www.tensorflow.org/datasets/catalog/sentiment140).\n",
    "</details>\n",
    "I suggest you to operate your preprocessing steps and then convert to a tensorflow dataset, which is the robust, and ready-to-parallel computing format you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uTKS4VOLrQJJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-21 18:14:03--  https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/training.1600000.processed.noemoticon.csv.zip\n",
      "Risoluzione di nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)... 162.243.189.2\n",
      "Connessione a nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)|162.243.189.2|:443... connesso.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 200 OK\n",
      "Lunghezza: 85088192 (81M) [application/zip]\n",
      "Salvataggio in: Â«data/training.1600000.processed.noemoticon.csv.zipÂ»\n",
      "\n",
      "training.1600000.pr 100%[===================>]  81,15M  4,73MB/s    in 23s     \n",
      "\n",
      "2021-05-21 18:14:26 (3,58 MB/s) - Â«data/training.1600000.processed.noemoticon.csv.zipÂ» salvato [85088192/85088192]\n",
      "\n",
      "Archive:  data/training.1600000.processed.noemoticon.csv.zip\n",
      "  inflating: data/training.1600000.processed.noemoticon.csv  \n"
     ]
    }
   ],
   "source": [
    "# Make data directory if it doesn't exist\n",
    "!mkdir -p data\n",
    "!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/training.1600000.processed.noemoticon.csv.zip -P data\n",
    "!unzip -n -d data data/training.1600000.processed.noemoticon.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzvOdqamtbD5"
   },
   "source": [
    "## Hardware suggestion\n",
    "\n",
    "I strongly advice to work in colab, or any other environment with a GPU available in order to minimise training time and being able to run multiple model training. \n",
    "Recall that experimenting is crucial.\n",
    "\n",
    "To check whether your instance has a GPU activated you can run the following code\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:    \n",
    "    raise SystemError('GPU device not found')\n",
    "```\n",
    "\n",
    "If you do not have the GPU enabled, just go to:\n",
    "\n",
    "`Edit -> Notebook Settings -> Hardware accelerator -> Set to GPU`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lebYFI3su3fz"
   },
   "source": [
    "### Questions to answer\n",
    "\n",
    "1. Is the dataset balanced?\n",
    "2. What kind of preprocessing you think is necessary?\n",
    "3. Can you use some sort of transfer learning? Which one?\n",
    "4. How many items contains the word \"*bush*\"?\n",
    "5. How many items containing the word \"*pussy*\" are classified as \"positive\"?\n",
    "6. How many items are classified as \"neutral\" and do not contain the words \"phone\", \"computer\", \"President\" and \"suck\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVqk_vl8w6D4"
   },
   "source": [
    "## General assignements\n",
    "\n",
    "* Write your code following [PEP8 style guide](https://www.python.org/dev/peps/pep-0008/).\n",
    "* Docstrings has to be written in [Google Style](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html).\n",
    "* It is strongly adviced to write your modules to collect functions and import them in the notebook (this will make the following point almost effortless). To import custom modules in colab [look at this example](https://colab.research.google.com/drive/1uvHuizCBqFgvbCwEhK7FvU8JW0AfxgJw#scrollTo=psH0aLrvoh78).\n",
    "* Once you are sure the notebook runs smoothly, write a python script to be executed from a command line interpreter to train your model:\n",
    "\n",
    "```bash\n",
    "python3 -m train --conf config.yml\n",
    "```\n",
    "\n",
    "The `config.yml` file has to contain configuration instructions on model architecture (kind of layers, number of layers, number of units, activations, etc.), on training (number of epochs, size of batches, if apply early stopping, optimiser, etc.) and on script metadata (where to get data, where to save output model).\n",
    "\n",
    "* Finally (optionally), you can serve your model on a webpage thanks to tensorflow.js."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<div style=\"margin: 0 auto; text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/oscar-defelice/DeepLearning-lectures/blob/master/src/FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOYO1Zs3+UBxLp5PuEmyhd2",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FinalProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
