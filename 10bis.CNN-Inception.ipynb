{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.domsoria.com/wp-content/uploads/2019/11/keras.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception Network\n",
    "\n",
    "The Inception network was an important milestone in the development of CNN classifiers. Prior to its inception (pun intended), most popular CNNs just stacked convolution layers deeper and deeper, hoping to get better performance.\n",
    "\n",
    "The Inception network on the other hand, was complex (heavily engineered). It used a lot of tricks to push performance; both in terms of speed and accuracy. Its constant evolution lead to the creation of several versions of the network. The popular versions are as follows\n",
    "* Inception v1\n",
    "* Inception v2\n",
    "* Inception v3\n",
    "* Inception v4\n",
    "* Inception ResNet\n",
    "\n",
    "## Which problems lead to Inception networks? \n",
    "\n",
    "Before digging into Inception Networks (yes, the name comes from the movie), it might be useful studying why an inception network was needed.\n",
    "\n",
    "#### Fun Fact\n",
    "The meme is referred in the [original paper](https://arxiv.org/pdf/1409.4842v1.pdf).\n",
    "![](https://miro.medium.com/max/1024/1*cwR_ezx0jliDvVUV6yno5g.jpeg)\n",
    "\n",
    "### Problems\n",
    "1. Salient parts in the image can have extremely large variation in size. For instance, an image with a dog can be either of the following, as shown below. The area occupied by the dog is different in each image.\n",
    "![](https://miro.medium.com/max/1400/1*aBdPBGAeta-_AM4aEyqeTQ.jpeg)\n",
    "2. Because of this huge variation in the location of the information, choosing the right kernel size for the convolution operation becomes tough. A larger kernel is preferred for information that is distributed more globally, and a smaller kernel is preferred for information that is distributed more locally.\n",
    "3. Very deep networks are prone to overfitting. It also hard to pass gradient updates through the entire network.\n",
    "4. Naively stacking large convolution operations is computationally expensive.\n",
    "\n",
    "### Solution!\n",
    "\n",
    "__Inception module__\n",
    "\n",
    "Why not have filters with multiple sizes operate on the same level? The network essentially would get a bit “wider” rather than “deeper”. The authors designed the inception module to reflect the same.\n",
    "\n",
    "![](https://i.ytimg.com/vi/KfV8CJh7hE0/maxresdefault.jpg)\n",
    "\n",
    "## Inception v1\n",
    "\n",
    "![](images/Inception_module1.jpg)\n",
    "\n",
    "Consider as example just the $5\\times5$ convolution,\n",
    "\n",
    "![](images/Inception_module2.jpg)\n",
    "\n",
    "\n",
    "As stated before, deep neural networks are **computationally expensive**. To make it cheaper, the authors limit the number of input channels by adding an extra $1\\times1$ convolution before the $3\\times3$ and $5\\times5$ convolutions. Though adding an extra operation may seem counterintuitive, $1\\times1$ convolutions are far more cheaper than $5\\times5$ convolutions, and the reduced number of input channels also help. Do note that however, the $1\\times1$ convolution is introduced after the max pooling layer, rather than before.\n",
    "\n",
    "![](images/Inception_module3.jpg)\n",
    "\n",
    "### GoogLeNet\n",
    "\n",
    "Using dimensional reduction a very populsr architecture was built, _GoogLeNet_.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*uW81y16b-ptBDV8SIT1beQ.png\" style=\"width:750px;height:300px;\">\n",
    "<center><small> GoogLeNet. The orange box is the stem, which has some preliminary convolutions. The purple boxes are auxiliary classifiers. The wide parts are the inception modules. (Source: Inception v1)<\\small><\\center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet has 9 inception modules stacked linearly. It is 22 layers deep (27, including the pooling layers). It uses global average pooling at the end of the last inception module.\n",
    "\n",
    "Of course, it is a pretty deep classifier. As with any very deep network, it is subject to the vanishing gradient problem.\n",
    "To prevent the middle part of the network from “dying out”, the authors introduced two auxiliary classifiers (The purple boxes in the image). They essentially applied softmax to the outputs of two of the inception modules, and computed an auxiliary loss over the same labels. The total loss function is a weighted sum of the auxiliary loss and the real loss. Weight value used in the paper was 0.3 for each auxiliary loss.\n",
    "\n",
    "## Inception v2 and v3\n",
    "\n",
    "These two further version of the inception module were presented in the same [paper](https://arxiv.org/pdf/1512.00567v3.pdf).\n",
    "\n",
    "### The Premise:\n",
    "Reduce representational bottleneck. The intuition was that, neural networks perform better when convolutions didn’t alter the dimensions of the input drastically. Reducing the dimensions too much may cause loss of information, known as a “representational bottleneck”\n",
    "\n",
    "Using smart factorization methods, convolutions can be made more efficient in terms of computational complexity.\n",
    "\n",
    "### Solution\n",
    "![](https://miro.medium.com/max/1114/1*RzvmmEQH_87qKWYBFIG_DA.png)\n",
    "\n",
    "* Authors noticed how a $5\\times5$ convolution is more than two times more expensive than a $3\\times3$ convolution: hence they substituted a $5\\times5$ block with two stacked $3\\times3$.\n",
    "\n",
    "* Moreover, they factorize convolutions of filter size $n\\times n$ to a combination of $1\\times n$ and $n\\times 1$ convolutions. For example, a $3\\times 3$ convolution is equivalent to first performing a $1\\times 3$ convolution, and then performing a $3\\times 1$ convolution on its output. They found this method to be $33\\%$ more cheaper than the single $3\\times 3$ convolution. This is illustrated in the below image.\n",
    "\n",
    "![](https://miro.medium.com/max/1196/1*hTwo-hy9BUZ1bYkzisL1KA.png)\n",
    "\n",
    "All of this stack together leads to the following scheme\n",
    "\n",
    "![](https://miro.medium.com/max/1150/1*DVXTxBwe_KUvpEs3ZXXFbg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another important point: Average pooling\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*0-wMHcASLDFzx9YBRCZXHg.png)\n",
    "\n",
    "Previously, we have seen fully connected (FC) layers are used at the end of network, such as in AlexNet. All inputs are connected to each output.\n",
    "\n",
    "* FC: __Number of weights (connections) = 7×7×1024×1024 = 51.3M__\n",
    "\n",
    "* GoogLeNet: global average pooling is used nearly at the end of network by averaging each feature map from 7×7 to 1×1, as in the figure above.\n",
    " __Number of weights = 0__\n",
    " \n",
    "And authors found that a move from FC layers to average pooling improved the top-1 accuracy by about 0.6%.\n",
    "\n",
    "This makes the final layer have a regularisation effect, and GoogLeNet is less prone to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Implementation of GoogLeNet in Keras\n",
    "\n",
    "We will use the CIFAR-10 dataset for this purpose.\n",
    "\n",
    "CIFAR-10 (Canadian Institute For Advanced Research) is a popular image classification dataset. It consists of 60,000 images of 10 classes (each class is represented as a row in the above image). The dataset is divided into 50,000 training images and 10,000 test images.\n",
    "\n",
    "The dataset is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. The CIFAR-10 dataset contains $60,000$ $32\\times32$ color images in $10$ different classes. The 10 different classes can be represented by a list \n",
    "```\n",
    "classes = ['airplanes', 'cars', 'birds', 'cats', 'deer', 'dogs', 'frogs', 'horses', 'ships', 'trucks']\n",
    "``` \n",
    "There are $6,000$ images of each class.\n",
    "\n",
    "Computer algorithms for recognizing objects in photos often learn by example. CIFAR-10 is a set of images that can be used to teach a computer how to recognize objects. Since the images in CIFAR-10 are low-resolution ($32\\times32$), this dataset can allow researchers to quickly try different algorithms to see what works. Various kinds of convolutional neural networks tend to be the best at recognizing the images in CIFAR-10.\n",
    "\n",
    "CIFAR-10 is a labeled subset of the $80$ million tiny images dataset. When the dataset was created, students were paid to label all of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Lambda\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Input, concatenate, GlobalAveragePooling2D, AveragePooling2D, Flatten\n",
    "\n",
    "import numpy as np \n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import math \n",
    "from tensorflow.keras.optimizers import SGD \n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's define a function to load the dataset in the proper form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "def load_cifar10_data():\n",
    "\n",
    "    # Load cifar10 training and validation sets\n",
    "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
    "\n",
    "    # Transform targets to keras compatible format\n",
    "    Y_train = to_categorical(Y_train, num_classes)\n",
    "    Y_valid = to_categorical(Y_valid, num_classes)\n",
    "    \n",
    "    X_train = X_train.astype('float32')\n",
    "    X_valid = X_valid.astype('float32')\n",
    "    \n",
    "    # Rescale training images\n",
    "    X_train /=255.\n",
    "    X_valid /=255.\n",
    "\n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_cifar10_data(224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define our deep learning architecture. We will quickly define a function to do this, which, when given the necessary information, gives us back the entire inception layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(x,\n",
    "                     filters_1x1,\n",
    "                     filters_3x3_reduce,\n",
    "                     filters_3x3,\n",
    "                     filters_5x5_reduce,\n",
    "                     filters_5x5,\n",
    "                     filters_pool_proj,\n",
    "                     name=None):\n",
    "    \n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    \n",
    "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)\n",
    "\n",
    "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)\n",
    "\n",
    "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n",
    "\n",
    "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then create the GoogLeNet architecture, as mentioned in the paper.\n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-16-11-56-41.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = tf.keras.initializers.GlorotUniform()\n",
    "bias_init = tf.keras.initializers.Constant(value=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model\n",
    "\n",
    "input_layer = Input(shape=(32, 32, 3))\n",
    "input_resize = Lambda(lambda image: tf.image.resize(image, (224, 224)))(input_layer)\n",
    "\n",
    "x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_resize)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
    "x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n",
    "x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=64,\n",
    "                     filters_3x3_reduce=96,\n",
    "                     filters_3x3=128,\n",
    "                     filters_5x5_reduce=16,\n",
    "                     filters_5x5=32,\n",
    "                     filters_pool_proj=32,\n",
    "                     name='inception_3a')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=128,\n",
    "                     filters_3x3_reduce=128,\n",
    "                     filters_3x3=192,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=96,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_3b')\n",
    "\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=192,\n",
    "                     filters_3x3_reduce=96,\n",
    "                     filters_3x3=208,\n",
    "                     filters_5x5_reduce=16,\n",
    "                     filters_5x5=48,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4a')\n",
    "\n",
    "\n",
    "x1 = AveragePooling2D((5, 5), strides=3)(x)\n",
    "x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n",
    "x1 = Flatten()(x1)\n",
    "x1 = Dense(1024, activation='relu')(x1)\n",
    "x1 = Dropout(0.7)(x1)\n",
    "x1 = Dense(10, activation='softmax', name='auxilliary_output_1')(x1)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=160,\n",
    "                     filters_3x3_reduce=112,\n",
    "                     filters_3x3=224,\n",
    "                     filters_5x5_reduce=24,\n",
    "                     filters_5x5=64,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4b')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=128,\n",
    "                     filters_3x3_reduce=128,\n",
    "                     filters_3x3=256,\n",
    "                     filters_5x5_reduce=24,\n",
    "                     filters_5x5=64,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4c')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=112,\n",
    "                     filters_3x3_reduce=144,\n",
    "                     filters_3x3=288,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=64,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4d')\n",
    "\n",
    "\n",
    "x2 = AveragePooling2D((5, 5), strides=3)(x)\n",
    "x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n",
    "x2 = Flatten()(x2)\n",
    "x2 = Dense(1024, activation='relu')(x2)\n",
    "x2 = Dropout(0.7)(x2)\n",
    "x2 = Dense(10, activation='softmax', name='auxilliary_output_2')(x2)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=256,\n",
    "                     filters_3x3_reduce=160,\n",
    "                     filters_3x3=320,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=128,\n",
    "                     filters_pool_proj=128,\n",
    "                     name='inception_4e')\n",
    "\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=256,\n",
    "                     filters_3x3_reduce=160,\n",
    "                     filters_3x3=320,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=128,\n",
    "                     filters_pool_proj=128,\n",
    "                     name='inception_5a')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=384,\n",
    "                     filters_3x3_reduce=192,\n",
    "                     filters_3x3=384,\n",
    "                     filters_5x5_reduce=48,\n",
    "                     filters_5x5=128,\n",
    "                     filters_pool_proj=128,\n",
    "                     name='inception_5b')\n",
    "\n",
    "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Dense(10, activation='softmax', name='output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_layer, [x, x1, x2], name='inception_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_7x7/2 (Conv2D)           (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_1_3x3/2 (MaxPooling2D) (None, 56, 56, 64)   0           conv_1_7x7/2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2a_3x3/1 (Conv2D)          (None, 56, 56, 64)   4160        max_pool_1_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_2b_3x3/1 (Conv2D)          (None, 56, 56, 192)  110784      conv_2a_3x3/1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_2_3x3/2 (MaxPooling2D) (None, 28, 28, 192)  0           conv_2b_3x3/1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 96)   18528       max_pool_2_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 16)   3088        max_pool_2_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 192)  0           max_pool_2_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 64)   12352       max_pool_2_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 128)  110720      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 32)   12832       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 28, 28, 32)   6176        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a (Concatenate)      (None, 28, 28, 256)  0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 128)  32896       inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 28, 28, 32)   8224        inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 256)  0           inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 128)  32896       inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 192)  221376      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 96)   76896       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 64)   16448       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b (Concatenate)      (None, 28, 28, 480)  0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_3_3x3/2 (MaxPooling2D) (None, 14, 14, 480)  0           inception_3b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 14, 14, 96)   46176       max_pool_3_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 14, 14, 16)   7696        max_pool_3_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 480)  0           max_pool_3_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 14, 14, 192)  92352       max_pool_3_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 14, 14, 208)  179920      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 14, 14, 48)   19248       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 14, 14, 64)   30784       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a (Concatenate)      (None, 14, 14, 512)  0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 14, 14, 112)  57456       inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 14, 14, 24)   12312       inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 14, 14, 160)  82080       inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 14, 14, 224)  226016      conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 14, 14, 64)   38464       conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b (Concatenate)      (None, 14, 14, 512)  0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 14, 14, 128)  65664       inception_4b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 24)   12312       inception_4b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 128)  65664       inception_4b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 14, 14, 256)  295168      conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 64)   38464       conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c (Concatenate)      (None, 14, 14, 512)  0           conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 144)  73872       inception_4c[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 32)   16416       inception_4c[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4c[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 112)  57456       inception_4c[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 288)  373536      conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 64)   51264       conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d (Concatenate)      (None, 14, 14, 528)  0           conv2d_32[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 160)  84640       inception_4d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 32)   16928       inception_4d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 14, 14, 528)  0           inception_4d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 256)  135424      inception_4d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 320)  461120      conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 128)  102528      conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 14, 14, 128)  67712       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e (Concatenate)      (None, 14, 14, 832)  0           conv2d_39[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_4_3x3/2 (MaxPooling2D) (None, 7, 7, 832)    0           inception_4e[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    133280      max_pool_4_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 32)     26656       max_pool_4_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 7, 7, 832)    0           max_pool_4_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 256)    213248      max_pool_4_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 320)    461120      conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 128)    102528      conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a (Concatenate)      (None, 7, 7, 832)    0           conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 192)    159936      inception_5a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 48)     39984       inception_5a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 7, 7, 832)    0           inception_5a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 4, 4, 512)    0           inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 528)    0           inception_4d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 384)    319872      inception_5a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 384)    663936      conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 128)    153728      conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 128)    65664       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 4, 4, 128)    67712       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b (Concatenate)      (None, 7, 7, 1024)   0           conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool_5_3x3/1 (GlobalAverage (None, 1024)         0           inception_5b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         2098176     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           avg_pool_5_3x3/1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 10)           10250       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "auxilliary_output_1 (Dense)     (None, 10)           10250       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "auxilliary_output_2 (Dense)     (None, 10)           10250       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,334,030\n",
      "Trainable params: 10,334,030\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model looks fine, as you can gauge from the above output. \n",
    "We can add a few finishing touches before we train our model. We will define the following:\n",
    "* Loss function for each output layer\n",
    "* Weightage assigned to that output layer\n",
    "* Optimization function, which is modified to include a weight decay after every 8 epochs\n",
    "* Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "initial_lrate = 0.01\n",
    "\n",
    "def decay(epoch, steps=100):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.96\n",
    "    epochs_drop = 8\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "sgd = SGD(lr=initial_lrate, momentum=0.9, nesterov=False)\n",
    "\n",
    "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
    "\n",
    "model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy'], loss_weights=[1, 0.3, 0.3], optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is now ready to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.01.\n",
      "50000/50000 [==============================] - 1860s 37ms/step - loss: 3.5701 - output_loss: 2.2360 - auxilliary_output_1_loss: 2.2164 - auxilliary_output_2_loss: 2.2265 - output_accuracy: 0.1483 - auxilliary_output_1_accuracy: 0.1616 - auxilliary_output_2_accuracy: 0.1479 - val_loss: 3.1966 - val_output_loss: 2.0039 - val_auxilliary_output_1_loss: 1.9702 - val_auxilliary_output_2_loss: 1.9772 - val_output_accuracy: 0.2443 - val_auxilliary_output_1_accuracy: 0.2652 - val_auxilliary_output_2_accuracy: 0.2514\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.01.\n",
      "50000/50000 [==============================] - 1860s 37ms/step - loss: 3.1228 - output_loss: 1.9567 - auxilliary_output_1_loss: 1.9364 - auxilliary_output_2_loss: 1.9520 - output_accuracy: 0.2639 - auxilliary_output_1_accuracy: 0.2850 - auxilliary_output_2_accuracy: 0.2739 - val_loss: 2.8625 - val_output_loss: 1.7915 - val_auxilliary_output_1_loss: 1.7528 - val_auxilliary_output_2_loss: 1.7748 - val_output_accuracy: 0.3171 - val_auxilliary_output_1_accuracy: 0.3683 - val_auxilliary_output_2_accuracy: 0.3454\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.01.\n",
      "50000/50000 [==============================] - 1857s 37ms/step - loss: 2.8289 - output_loss: 1.7754 - auxilliary_output_1_loss: 1.7514 - auxilliary_output_2_loss: 1.7584 - output_accuracy: 0.3370 - auxilliary_output_1_accuracy: 0.3604 - auxilliary_output_2_accuracy: 0.3554 - val_loss: 2.5674 - val_output_loss: 1.6163 - val_auxilliary_output_1_loss: 1.5755 - val_auxilliary_output_2_loss: 1.5707 - val_output_accuracy: 0.3983 - val_auxilliary_output_1_accuracy: 0.4315 - val_auxilliary_output_2_accuracy: 0.4251\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.01.\n",
      "50000/50000 [==============================] - 1858s 37ms/step - loss: 2.5675 - output_loss: 1.6067 - auxilliary_output_1_loss: 1.6030 - auxilliary_output_2_loss: 1.6024 - output_accuracy: 0.4015 - auxilliary_output_1_accuracy: 0.4139 - auxilliary_output_2_accuracy: 0.4094 - val_loss: 2.2902 - val_output_loss: 1.4333 - val_auxilliary_output_1_loss: 1.4267 - val_auxilliary_output_2_loss: 1.4236 - val_output_accuracy: 0.4686 - val_auxilliary_output_1_accuracy: 0.4830 - val_auxilliary_output_2_accuracy: 0.4710\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.01.\n",
      "50000/50000 [==============================] - 1858s 37ms/step - loss: 2.3526 - output_loss: 1.4654 - auxilliary_output_1_loss: 1.4802 - auxilliary_output_2_loss: 1.4772 - output_accuracy: 0.4572 - auxilliary_output_1_accuracy: 0.4589 - auxilliary_output_2_accuracy: 0.4547 - val_loss: 2.2563 - val_output_loss: 1.4410 - val_auxilliary_output_1_loss: 1.3526 - val_auxilliary_output_2_loss: 1.3507 - val_output_accuracy: 0.4403 - val_auxilliary_output_1_accuracy: 0.4984 - val_auxilliary_output_2_accuracy: 0.4988\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.01.\n",
      "50000/50000 [==============================] - 1892s 38ms/step - loss: 2.1583 - output_loss: 1.3347 - auxilliary_output_1_loss: 1.3880 - auxilliary_output_2_loss: 1.3573 - output_accuracy: 0.5077 - auxilliary_output_1_accuracy: 0.4954 - auxilliary_output_2_accuracy: 0.5027 - val_loss: 2.0131 - val_output_loss: 1.2610 - val_auxilliary_output_1_loss: 1.2765 - val_auxilliary_output_2_loss: 1.2405 - val_output_accuracy: 0.5367 - val_auxilliary_output_1_accuracy: 0.5353 - val_auxilliary_output_2_accuracy: 0.5420\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.01.\n",
      "50000/50000 [==============================] - 1861s 37ms/step - loss: 1.9579 - output_loss: 1.1956 - auxilliary_output_1_loss: 1.2988 - auxilliary_output_2_loss: 1.2406 - output_accuracy: 0.5618 - auxilliary_output_1_accuracy: 0.5310 - auxilliary_output_2_accuracy: 0.5464 - val_loss: 1.7954 - val_output_loss: 1.1060 - val_auxilliary_output_1_loss: 1.2002 - val_auxilliary_output_2_loss: 1.1114 - val_output_accuracy: 0.6038 - val_auxilliary_output_1_accuracy: 0.5693 - val_auxilliary_output_2_accuracy: 0.6027\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0096.\n",
      "50000/50000 [==============================] - 1863s 37ms/step - loss: 1.8059 - output_loss: 1.0919 - auxilliary_output_1_loss: 1.2276 - auxilliary_output_2_loss: 1.1559 - output_accuracy: 0.6054 - auxilliary_output_1_accuracy: 0.5626 - auxilliary_output_2_accuracy: 0.5837 - val_loss: 1.7753 - val_output_loss: 1.1120 - val_auxilliary_output_1_loss: 1.1346 - val_auxilliary_output_2_loss: 1.0562 - val_output_accuracy: 0.6028 - val_auxilliary_output_1_accuracy: 0.5984 - val_auxilliary_output_2_accuracy: 0.6265\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0096.\n",
      "50000/50000 [==============================] - 1863s 37ms/step - loss: 1.6786 - output_loss: 1.0095 - auxilliary_output_1_loss: 1.1541 - auxilliary_output_2_loss: 1.0756 - output_accuracy: 0.6400 - auxilliary_output_1_accuracy: 0.5901 - auxilliary_output_2_accuracy: 0.6154 - val_loss: 1.5586 - val_output_loss: 0.9518 - val_auxilliary_output_1_loss: 1.0566 - val_auxilliary_output_2_loss: 0.9806 - val_output_accuracy: 0.6580 - val_auxilliary_output_1_accuracy: 0.6206 - val_auxilliary_output_2_accuracy: 0.6475\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0096.\n",
      "50000/50000 [==============================] - 1863s 37ms/step - loss: 1.5280 - output_loss: 0.9069 - auxilliary_output_1_loss: 1.0745 - auxilliary_output_2_loss: 0.9927 - output_accuracy: 0.6780 - auxilliary_output_1_accuracy: 0.6180 - auxilliary_output_2_accuracy: 0.6469 - val_loss: 1.6054 - val_output_loss: 1.0015 - val_auxilliary_output_1_loss: 1.0362 - val_auxilliary_output_2_loss: 0.9868 - val_output_accuracy: 0.6468 - val_auxilliary_output_1_accuracy: 0.6291 - val_auxilliary_output_2_accuracy: 0.6475\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0096.\n",
      "50000/50000 [==============================] - 1888s 38ms/step - loss: 1.4138 - output_loss: 0.8328 - auxilliary_output_1_loss: 1.0130 - auxilliary_output_2_loss: 0.9208 - output_accuracy: 0.7055 - auxilliary_output_1_accuracy: 0.6415 - auxilliary_output_2_accuracy: 0.6729 - val_loss: 1.4452 - val_output_loss: 0.8857 - val_auxilliary_output_1_loss: 0.9466 - val_auxilliary_output_2_loss: 0.9189 - val_output_accuracy: 0.6828 - val_auxilliary_output_1_accuracy: 0.6593 - val_auxilliary_output_2_accuracy: 0.6646\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0096.\n",
      "50000/50000 [==============================] - 1877s 38ms/step - loss: 1.3037 - output_loss: 0.7590 - auxilliary_output_1_loss: 0.9590 - auxilliary_output_2_loss: 0.8589 - output_accuracy: 0.7329 - auxilliary_output_1_accuracy: 0.6606 - auxilliary_output_2_accuracy: 0.6954 - val_loss: 1.5706 - val_output_loss: 1.0460 - val_auxilliary_output_1_loss: 0.8897 - val_auxilliary_output_2_loss: 0.8879 - val_output_accuracy: 0.6438 - val_auxilliary_output_1_accuracy: 0.6843 - val_auxilliary_output_2_accuracy: 0.6877\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0096.\n",
      "50000/50000 [==============================] - 1873s 37ms/step - loss: 1.2142 - output_loss: 0.7005 - auxilliary_output_1_loss: 0.9071 - auxilliary_output_2_loss: 0.8048 - output_accuracy: 0.7549 - auxilliary_output_1_accuracy: 0.6787 - auxilliary_output_2_accuracy: 0.7141 - val_loss: 1.2109 - val_output_loss: 0.7339 - val_auxilliary_output_1_loss: 0.8298 - val_auxilliary_output_2_loss: 0.7770 - val_output_accuracy: 0.7433 - val_auxilliary_output_1_accuracy: 0.7080 - val_auxilliary_output_2_accuracy: 0.7254\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0096.\n",
      "50000/50000 [==============================] - 1875s 37ms/step - loss: 1.1345 - output_loss: 0.6465 - auxilliary_output_1_loss: 0.8699 - auxilliary_output_2_loss: 0.7554 - output_accuracy: 0.7729 - auxilliary_output_1_accuracy: 0.6942 - auxilliary_output_2_accuracy: 0.7322 - val_loss: 1.3288 - val_output_loss: 0.8369 - val_auxilliary_output_1_loss: 0.8699 - val_auxilliary_output_2_loss: 0.7733 - val_output_accuracy: 0.6996 - val_auxilliary_output_1_accuracy: 0.6927 - val_auxilliary_output_2_accuracy: 0.7247\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0096.\n",
      "50000/50000 [==============================] - 1874s 37ms/step - loss: 1.0600 - output_loss: 0.5971 - auxilliary_output_1_loss: 0.8310 - auxilliary_output_2_loss: 0.7094 - output_accuracy: 0.7908 - auxilliary_output_1_accuracy: 0.7071 - auxilliary_output_2_accuracy: 0.7500 - val_loss: 1.0733 - val_output_loss: 0.6402 - val_auxilliary_output_1_loss: 0.7774 - val_auxilliary_output_2_loss: 0.6913 - val_output_accuracy: 0.7799 - val_auxilliary_output_1_accuracy: 0.7260 - val_auxilliary_output_2_accuracy: 0.7550\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.009216.\n",
      "50000/50000 [==============================] - 1872s 37ms/step - loss: 0.9716 - output_loss: 0.5352 - auxilliary_output_1_loss: 0.7940 - auxilliary_output_2_loss: 0.6605 - output_accuracy: 0.8139 - auxilliary_output_1_accuracy: 0.7212 - auxilliary_output_2_accuracy: 0.7667 - val_loss: 1.1341 - val_output_loss: 0.6962 - val_auxilliary_output_1_loss: 0.7640 - val_auxilliary_output_2_loss: 0.7010 - val_output_accuracy: 0.7558 - val_auxilliary_output_1_accuracy: 0.7338 - val_auxilliary_output_2_accuracy: 0.7523\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.009216.\n",
      "36352/50000 [====================>.........] - ETA: 8:01 - loss: 0.9486 - output_loss: 0.5238 - auxilliary_output_1_loss: 0.7712 - auxilliary_output_2_loss: 0.6446 - output_accuracy: 0.8157 - auxilliary_output_1_accuracy: 0.7313 - auxilliary_output_2_accuracy: 0.7740"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, [y_train, y_train, y_train], validation_data=(X_test, [y_test, y_test, y_test]), \n",
    "                    epochs=epochs, batch_size=256, callbacks=[lr_sc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception-ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by the performance of the ResNet, a hybrid inception module was proposed. There are two sub-versions of Inception ResNet, namely v1 and v2. The former has computational performances similat to Inception v3, while the latter to Inception v4.\n",
    "\n",
    "Here a scheme of the inception block with skip connections.\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*WyqyCKA4mP1jsl8H4eHrjg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To go deeper 😉\n",
    "\n",
    "One can read this excellent [post](https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "* [Inception paper](https://arxiv.org/pdf/1409.4842v1.pdf)\n",
    "* [Inception v2 and v3 paper](https://arxiv.org/pdf/1512.00567v3.pdf)\n",
    "* [Inception v4 and Inception-ResNet paper](https://arxiv.org/pdf/1602.07261.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lectures",
   "language": "python",
   "name": "lectures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
