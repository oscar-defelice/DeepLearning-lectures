{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.domsoria.com/wp-content/uploads/2019/11/keras.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution (again)\n",
    "\n",
    "__Why we use convolution to analyse images?__\n",
    "\n",
    "Consider a very famous case of CNN architecture: [LeNet-5](https://en.wikipedia.org/wiki/LeNet)\n",
    "![](https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png)\n",
    "\n",
    "Consider the first layer.\n",
    "\n",
    "\n",
    "<img src=\"images/LeNet5-1.png\" style=\"width:500px;height:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1__\n",
    "\n",
    "> How many weights has this first convolutional Layer?\n",
    "\n",
    "\n",
    "_Answer_\n",
    "\n",
    "$$\\left(k \\times k \\times n_C + b \\right) \\times n_f = \\left(5 \\times 5 \\times 3 + 1\\right) \\times 6 = 456$$\n",
    "\n",
    "![](images/LeNet5-weights.png)\n",
    "\n",
    "\n",
    "__Question 2__\n",
    "\n",
    "> If instead of convolution, we use the classical dense (Fully Connected) layers, with $32\\times 32 \\times 3 = 3072$ inputs and $28\\times 28 \\times 6 = 4704$ outputs how many weights we would need?\n",
    "\n",
    "\n",
    "_Answer_\n",
    "\n",
    "$\\sim 14$ million of weights.\n",
    "\n",
    "**Note** The whole _LeNet-5_ network has $\\sim 6 \\cdot 10^4$ weights.\n",
    "\n",
    "\n",
    "## Other Reasons to use Convolution\n",
    "\n",
    "### Parameter sharing \n",
    "\n",
    "Convolution allows to use shallower layers to detect low-complexity features, and deeper layers to encode more complex skills. This makes the shallow layers feature detectors shared in different part of the same image, later in depth.\n",
    "\n",
    "### Sparsity of connections\n",
    "\n",
    "In each layer, each output depends only on a small number of inputs.\n",
    "\n",
    "\n",
    "Both these properties are numerically useful, because they make CNN have few parameters with respect to a Dense (plain) neural network.\n",
    "\n",
    "## Other important CNN classical configurations\n",
    "\n",
    "1. [LeNet-5](https://www.mitpressjournals.org/doi/10.1162/neco.1989.1.4.541): [Keras implementation](https://github.com/TaavishThaman/LeNet-5-with-Keras)\n",
    "![](https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png)\n",
    "2. [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf): [Keras implementation](https://github.com/duggalrahul/AlexNet-Experiments-Keras)\n",
    "![](https://andreaprovino.it/wp-content/uploads/2020/02/alexnet-architecture-deep-learning-engineer-italia-cnn-network-example-architecture-diagram.png)\n",
    "3. [VGG-16](https://arxiv.org/abs/1409.1556): [Keras implementation](https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg16.py)\n",
    "![](https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Networks\n",
    "\n",
    "A really important computational improvement in neural networks is called __Residual Block__. This is in principle an application working in any kind of network, not only in CNN, but because of the amount of data involved in computer vision, these networks are incredibly important to perform complex tasks with sustainable costs.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*aqmUx_ONo8KqKNEYsjM8eA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The working principle\n",
    "\n",
    "Consider the following case.\n",
    "\n",
    "![](images/ResBlock.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a classic plain (fully connected) NN we have information flowing from $a^{[l]}$ to $a^{[l+2]}$ through the following path\n",
    "\n",
    "$$a^{[l]} \\rightarrow z^{[l+1]} \\rightarrow \\mathrm{ReLU} \\rightarrow a^{[l+1]} \\rightarrow z^{[l+2]} \\rightarrow \\mathrm{ReLU} \\rightarrow a^{[l+2]}$$\n",
    "\n",
    "such a scheme is called __main path__.\n",
    "\n",
    "In a __residual block__ we modify the path as follows\n",
    "\n",
    "![](images/ResConnection.png)\n",
    "\n",
    "One copies the value $a^{[l]}$ and pass it to the following activation before applying the activation function.\n",
    "\n",
    "The _feedforward equation_ gets modified as \n",
    "\n",
    "$$a^{[l+2]} = \\varphi(z^{[l+2]} + a^{[l]})$$ \n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*kanYOsFl0MmaPk5ZWDjJmw.png)\n",
    "\n",
    "A Residual Network is a concatenation of several residual blocks.\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*uyXEvYztiv3fGGCCPbm8Jg.png)\n",
    "<center> When x and x_shortcut have the same shape. <center>\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*U5wkA4O1IpY-ekXqFh0tUQ.png)\n",
    "<center> When you need to reshape x and x_shortcut. <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this useful?\n",
    "\n",
    "![](images/ResPerformance.png)\n",
    "\n",
    "In this way we add two extra-layers with almost no cost in training. Thus this increases the ability to learn complex features, without affecting performances too much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
